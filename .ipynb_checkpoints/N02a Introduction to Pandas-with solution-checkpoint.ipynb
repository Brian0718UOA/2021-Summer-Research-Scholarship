{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "Civil 774 - Smart Infrastructure Analytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://miro.medium.com/max/3006/1*KdxlBR9P3mDp9JZ_URMdYQ.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**pandas** is a Python package providing fast, flexible, and expressive data structures designed to work with *relational* or *labeled* data both. It is a fundamental high-level building block for doing practical, real world data analysis in Python. \n",
    "\n",
    "pandas is well suited for:\n",
    "\n",
    "- Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\n",
    "- Ordered and unordered (not necessarily fixed-frequency) time series data.\n",
    "- Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\n",
    "- Any other form of observational / statistical data sets. The data actually need not be labeled at all to be placed into a pandas data structure\n",
    "\n",
    "\n",
    "Key features:\n",
    "    \n",
    "- Easy handling of **missing data**\n",
    "- **Size mutability**: columns can be inserted and deleted from DataFrame and higher dimensional objects\n",
    "- Automatic and explicit **data alignment**: objects can be explicitly aligned to a set of labels, or the data can be aligned automatically\n",
    "- Powerful, flexible **group by functionality** to perform split-apply-combine operations on data sets\n",
    "- Intelligent label-based **slicing, fancy indexing, and subsetting** of large data sets\n",
    "- Intuitive **merging and joining** data sets\n",
    "- Flexible **reshaping and pivoting** of data sets\n",
    "- **Hierarchical labeling** of axes\n",
    "- Robust **IO tools** for loading data from flat files, Excel files, databases, and HDF5\n",
    "- **Time series functionality**: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging, etc.\n",
    "\n",
    "In this lecture, we will talk about: \n",
    "1. Pandas Data Structures\n",
    "2. Import data into Pandas\n",
    "3. Pandas fundamentals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pandas Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "A **Series** is a single vector of data (like an array) with an *index* that labels each element in the vector.\n",
    "\n",
    "Now first let's create a Pandas series with only numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.Series([43, 332, 75, 99])\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an index is not specified, a default sequence of integers is assigned as the index. A NumPy array comprises the values of the `Series`, while the index is a pandas `Index` object.\n",
    "\n",
    "Let's try to see only the values of a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to see only the indexes of a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index and slicing\n",
    "\n",
    "The indexes can be strings as well, so they can be more meaningful\n",
    "Now let's try that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price = pd.Series([1.2, 0.8, 1.1, 0.6], \n",
    "    index=['Auckland','Christchurch','Wellington','Hamilton'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These labels can be used to refer to the values in the `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price['Auckland']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the string indexes, we can easily find values using the index. For instance, let's try to find the index name end with letter \"d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price[[a.endswith('d') for a in Price.index]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still use positional indexing if we wish. Let's try to find the first second city in our series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing is the way we can take some data out of the series, and later on Dataframe, we talked briefly about this in the previous week but let's do it in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also see if we can add new data into this series. In pandas we can use the `.append` for this purpose. However, note that .append is not an in-place operation in Pandas. From the docs:\n",
    "\n",
    "    'Append rows of other to the end of this frame, returning a new object. Columns not in this frame are added as new columns.'\n",
    "\n",
    "We need to assign the result back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price = Price.append(pd.Series([1],index=[\"Gisborne\"]))\n",
    "Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and also drop or remove some values. Let's try to remove the last item that had been added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price=Price.drop('Gisborne')\n",
    "Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Python array to Pandas Series\n",
    "\n",
    "With Series contain values and indexes separately, we can convert a standard Python array into a Pandas series and provide new indexes\n",
    " Let's try that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array0 = [1571,369,203,161]\n",
    "pop = pd.Series(array0)\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.index = ['Auckland','Christchurch','Wellington','Hamilton']\n",
    "\n",
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine with other packages in Python, e.g. Numpy, to create series in Pandas, for instance, let's use another data analytics package `Numpy` to randomly create a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n0 = np.random.randn(4)\n",
    "index0=['Auckland','Christchurch','Wellington','Hamilton']\n",
    "s = pd.Series(n0,index=index0)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name the data and the index\n",
    "\n",
    "We can give both the array of values and the index meaningful labels themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.name = 'Population'\n",
    "pop.index.name = 'Cities'\n",
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the data\n",
    "\n",
    "Now let's try to filter cities with more than 350,000 people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop[pop>350]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "Inevitably, we want to be able to store, view and manipulate data that is *multivariate*, where for every index there are multiple fields or columns of data, often of varying data type.\n",
    "\n",
    "A `DataFrame` is a tabular data structure, encapsulating multiple series like columns in a spreadsheet. Data are stored internally as a 2-dimensional object, but the `DataFrame` allows us to represent and manipulate higher-dimensional data.\n",
    "\n",
    "### Create DataFrame\n",
    "\n",
    "We created some Series in the previous section, let's combine them as a new DataFrame (2-dimension Excel-spreadsheet-like data structure!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat ([Price,pop,s], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `DataFrame` is sorted by column name. We can change the order by indexing them in the order we desire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Price','Population','Score']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also rearrange the order of these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Population','Price','Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataFrame` has a second index, representing the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish to access columns, we can do so either by dict-like indexing or by attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify or add value to a Dataframe. Locate the index of a certain value by using `.loc` (if we have a string or mixed index), or `.iloc` if we use a numberic index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Auckland','Price']= 1.4\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important method to select data in `Pandas` is `.loc` and `.iloc`\n",
    "\n",
    "They enable us to access a group of rows and columns by label(s) or a boolean array.\n",
    "\n",
    "`.loc[]` is primarily label based, but may also be used with a boolean array.\n",
    "\n",
    "Allowed inputs are:\n",
    "\n",
    "* A single label, e.g. 5 or 'a', (note that 5 is interpreted as a label of the index, and never as an integer position along the index).\n",
    "\n",
    "* A list or array of labels, e.g. ['a', 'b', 'c'].\n",
    "\n",
    "* A slice object with labels, e.g. 'a':'f'.\n",
    "\n",
    "* A boolean array of the same length as the axis being sliced, e.g. [True, False, True].\n",
    "\n",
    "`.iloc[]` is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array.\n",
    "\n",
    "Allowed inputs are:\n",
    "\n",
    "* An integer, e.g. 5.\n",
    "\n",
    "* A list or array of integers, e.g. [4, 3, 0].\n",
    "\n",
    "* A slice object with ints, e.g. 1:7.\n",
    "\n",
    "* A boolean array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can just define a new column for the dataframe `df`to add a new column, but it either need to be the same length as the `DataFrame`, or should be just one similar value for the whole column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year']= 2021\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region = ['North', 'South']\n",
    "df['Region'] = Region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region = ['North', 'South', 'North','North']\n",
    "df['Island'] = Region\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previously when we worked with Series, we can also use `.drop` to remove columns or rows in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"year\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: How can you remove a row in Pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing data to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key, but often under-appreciated, step in data analysis is importing the data that we wish to analyze. Pandas provides a convenient set of functions for importing tabular data in a number of formats directly into a `DataFrame` object. These functions include a slew of options to perform type inference, indexing, parsing, iterating and cleaning automatically as data are imported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from text files such as CSV can be read into a DataFrame using `read_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/NZ_cars.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `read_csv` automatically considered the first row in the file to be a header row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the data types of the data by using `.dtypes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see the first 5 lines in the data, `pandas` has the function `.head()` to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the number of lines `.head()` displays by adding a number into it. For example here we show 10 first lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show the last X lines by `.tail(X)`, for instance the last 5 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show only one column, for instance let's show only the `BASIC_COLOUR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.BASIC_COLOUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way to do it:\n",
    "df['BASIC_COLOUR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the number of unique colours by using `nunique`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.BASIC_COLOUR.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And find out the most popular colour by `value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.BASIC_COLOUR.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_csv` is just a convenience function for `read_table`, since csv is such a common format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"../Data/NZ_cars.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sep` argument can be customized as needed to accomodate arbitrary separators. For example, we can use a regular expression to define a variable amount of whitespace, which is unfortunately very common in some data formats: \n",
    "    \n",
    "    sep='\\s+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more useful index, we can specify the first two columns as the indexes of our data, which together provide a unique index to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/NZ_cars.csv\", index_col=['BASIC_COLOUR','BODY_TYPE'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a *hierarchical* index, which we will revisit later in the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have sections of data that we do not wish to import (for example, known bad data), we can populate the `skiprows` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../Data/NZ_cars.csv\", skiprows=[3,4,6]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversely, if we only want to import a small number of rows from, say, a very large data file we can use `nrows`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"../Data/NZ_cars.csv\", nrows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most real-world data is incomplete, with values missing due to incomplete observation, data entry or transcription error, or other reasons. Pandas will automatically recognize and parse common missing data indicators, including `NA` and `NULL`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pandas Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section introduces the new user to the key functionality of Pandas that is required to use the software effectively.\n",
    "\n",
    "For some variety, we will now look at our Electricity generation data in NZ. Try to read the file `generation2.csv` in the Data folder. \n",
    "\n",
    "Note that this dataset is larger. It might take a few seconds to a minute of processing time just to read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_Code</th>\n",
       "      <th>POC_Code</th>\n",
       "      <th>Nwk_Code</th>\n",
       "      <th>Gen_Code</th>\n",
       "      <th>Fuel_Code</th>\n",
       "      <th>Tech_Code</th>\n",
       "      <th>Trading_date</th>\n",
       "      <th>TP1</th>\n",
       "      <th>TP2</th>\n",
       "      <th>TP3</th>\n",
       "      <th>...</th>\n",
       "      <th>TP39</th>\n",
       "      <th>TP40</th>\n",
       "      <th>TP41</th>\n",
       "      <th>TP42</th>\n",
       "      <th>TP43</th>\n",
       "      <th>TP44</th>\n",
       "      <th>TP45</th>\n",
       "      <th>TP46</th>\n",
       "      <th>TP47</th>\n",
       "      <th>TP48</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARA</td>\n",
       "      <td>ARA2201</td>\n",
       "      <td>MRPL</td>\n",
       "      <td>aratiatia</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>1/08/97</td>\n",
       "      <td>29230.0</td>\n",
       "      <td>29100.0</td>\n",
       "      <td>29470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35320</td>\n",
       "      <td>33900</td>\n",
       "      <td>33790</td>\n",
       "      <td>30310</td>\n",
       "      <td>27580</td>\n",
       "      <td>27110</td>\n",
       "      <td>27200</td>\n",
       "      <td>27310</td>\n",
       "      <td>27330</td>\n",
       "      <td>27260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG1101</td>\n",
       "      <td>TRUS</td>\n",
       "      <td>argyle_wairau</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>1/08/97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3928</td>\n",
       "      <td>3888</td>\n",
       "      <td>3892</td>\n",
       "      <td>908</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARI</td>\n",
       "      <td>ARI1101</td>\n",
       "      <td>MRPL</td>\n",
       "      <td>arapuni</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>1/08/97</td>\n",
       "      <td>81510.0</td>\n",
       "      <td>81330.0</td>\n",
       "      <td>64800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83180</td>\n",
       "      <td>83640</td>\n",
       "      <td>76160</td>\n",
       "      <td>72360</td>\n",
       "      <td>63180</td>\n",
       "      <td>62640</td>\n",
       "      <td>62310</td>\n",
       "      <td>63050</td>\n",
       "      <td>63130</td>\n",
       "      <td>54020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATI</td>\n",
       "      <td>ATI2201</td>\n",
       "      <td>MRPL</td>\n",
       "      <td>atiamuri</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>1/08/97</td>\n",
       "      <td>19200.0</td>\n",
       "      <td>15270.0</td>\n",
       "      <td>15030.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37420</td>\n",
       "      <td>34650</td>\n",
       "      <td>29350</td>\n",
       "      <td>29650</td>\n",
       "      <td>29670</td>\n",
       "      <td>23190</td>\n",
       "      <td>19910</td>\n",
       "      <td>17830</td>\n",
       "      <td>17930</td>\n",
       "      <td>17550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AVI2201</td>\n",
       "      <td>MERI</td>\n",
       "      <td>aviemore</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>1/08/97</td>\n",
       "      <td>87970.0</td>\n",
       "      <td>87880.0</td>\n",
       "      <td>87770.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81980</td>\n",
       "      <td>74380</td>\n",
       "      <td>67190</td>\n",
       "      <td>53040</td>\n",
       "      <td>45970</td>\n",
       "      <td>47080</td>\n",
       "      <td>50350</td>\n",
       "      <td>50870</td>\n",
       "      <td>51740</td>\n",
       "      <td>52350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site_Code POC_Code Nwk_Code       Gen_Code Fuel_Code Tech_Code  \\\n",
       "id                                                                  \n",
       "0        ARA  ARA2201     MRPL      aratiatia     Hydro     Hydro   \n",
       "1        NaN  ARG1101     TRUS  argyle_wairau     Hydro     Hydro   \n",
       "2        ARI  ARI1101     MRPL        arapuni     Hydro     Hydro   \n",
       "3        ATI  ATI2201     MRPL       atiamuri     Hydro     Hydro   \n",
       "4        NaN  AVI2201     MERI       aviemore     Hydro     Hydro   \n",
       "\n",
       "   Trading_date      TP1      TP2      TP3  ...   TP39   TP40   TP41   TP42  \\\n",
       "id                                          ...                               \n",
       "0       1/08/97  29230.0  29100.0  29470.0  ...  35320  33900  33790  30310   \n",
       "1       1/08/97      NaN      NaN      NaN  ...   3928   3888   3892    908   \n",
       "2       1/08/97  81510.0  81330.0  64800.0  ...  83180  83640  76160  72360   \n",
       "3       1/08/97  19200.0  15270.0  15030.0  ...  37420  34650  29350  29650   \n",
       "4       1/08/97  87970.0  87880.0  87770.0  ...  81980  74380  67190  53040   \n",
       "\n",
       "     TP43   TP44   TP45   TP46   TP47   TP48  \n",
       "id                                            \n",
       "0   27580  27110  27200  27310  27330  27260  \n",
       "1       6      0      0      0      0      0  \n",
       "2   63180  62640  62310  63050  63130  54020  \n",
       "3   29670  23190  19910  17830  17930  17550  \n",
       "4   45970  47080  50350  50870  51740  52350  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen = pd.read_csv(\"generation2.csv\", index_col=\"id\")\n",
    "df_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Manipulating indices\n",
    "\n",
    "**Reindexing** allows users to manipulate the data labels in a DataFrame. It forces a DataFrame to conform to the new index, and optionally, fill in missing data if requested.\n",
    "\n",
    "A simple use of `reindex` is to alter the order of the rows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we specified the `id` column as the index, since it appears to be a unique identifier. We could try to create a unique index ourselves by combining `Site_Code` and `POC_Code`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_Code</th>\n",
       "      <th>POC_Code</th>\n",
       "      <th>Nwk_Code</th>\n",
       "      <th>Gen_Code</th>\n",
       "      <th>Fuel_Code</th>\n",
       "      <th>Tech_Code</th>\n",
       "      <th>Trading_date</th>\n",
       "      <th>TP1</th>\n",
       "      <th>TP2</th>\n",
       "      <th>TP3</th>\n",
       "      <th>...</th>\n",
       "      <th>TP39</th>\n",
       "      <th>TP40</th>\n",
       "      <th>TP41</th>\n",
       "      <th>TP42</th>\n",
       "      <th>TP43</th>\n",
       "      <th>TP44</th>\n",
       "      <th>TP45</th>\n",
       "      <th>TP46</th>\n",
       "      <th>TP47</th>\n",
       "      <th>TP48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARAARA2201</th>\n",
       "      <td>ARA</td>\n",
       "      <td>ARA2201</td>\n",
       "      <td>MRPL</td>\n",
       "      <td>aratiatia</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>1/08/97</td>\n",
       "      <td>29230.0</td>\n",
       "      <td>29100.0</td>\n",
       "      <td>29470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35320</td>\n",
       "      <td>33900</td>\n",
       "      <td>33790</td>\n",
       "      <td>30310</td>\n",
       "      <td>27580</td>\n",
       "      <td>27110</td>\n",
       "      <td>27200</td>\n",
       "      <td>27310</td>\n",
       "      <td>27330</td>\n",
       "      <td>27260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG1101</td>\n",
       "      <td>TRUS</td>\n",
       "      <td>argyle_wairau</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>1/08/97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3928</td>\n",
       "      <td>3888</td>\n",
       "      <td>3892</td>\n",
       "      <td>908</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARIARI1101</th>\n",
       "      <td>ARI</td>\n",
       "      <td>ARI1101</td>\n",
       "      <td>MRPL</td>\n",
       "      <td>arapuni</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>1/08/97</td>\n",
       "      <td>81510.0</td>\n",
       "      <td>81330.0</td>\n",
       "      <td>64800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83180</td>\n",
       "      <td>83640</td>\n",
       "      <td>76160</td>\n",
       "      <td>72360</td>\n",
       "      <td>63180</td>\n",
       "      <td>62640</td>\n",
       "      <td>62310</td>\n",
       "      <td>63050</td>\n",
       "      <td>63130</td>\n",
       "      <td>54020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATIATI2201</th>\n",
       "      <td>ATI</td>\n",
       "      <td>ATI2201</td>\n",
       "      <td>MRPL</td>\n",
       "      <td>atiamuri</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>1/08/97</td>\n",
       "      <td>19200.0</td>\n",
       "      <td>15270.0</td>\n",
       "      <td>15030.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37420</td>\n",
       "      <td>34650</td>\n",
       "      <td>29350</td>\n",
       "      <td>29650</td>\n",
       "      <td>29670</td>\n",
       "      <td>23190</td>\n",
       "      <td>19910</td>\n",
       "      <td>17830</td>\n",
       "      <td>17930</td>\n",
       "      <td>17550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AVI2201</td>\n",
       "      <td>MERI</td>\n",
       "      <td>aviemore</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>1/08/97</td>\n",
       "      <td>87970.0</td>\n",
       "      <td>87880.0</td>\n",
       "      <td>87770.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81980</td>\n",
       "      <td>74380</td>\n",
       "      <td>67190</td>\n",
       "      <td>53040</td>\n",
       "      <td>45970</td>\n",
       "      <td>47080</td>\n",
       "      <td>50350</td>\n",
       "      <td>50870</td>\n",
       "      <td>51740</td>\n",
       "      <td>52350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Site_Code POC_Code Nwk_Code       Gen_Code Fuel_Code Tech_Code  \\\n",
       "ARAARA2201       ARA  ARA2201     MRPL      aratiatia     Hydro     Hydro   \n",
       "NaN              NaN  ARG1101     TRUS  argyle_wairau     Hydro     Hydro   \n",
       "ARIARI1101       ARI  ARI1101     MRPL        arapuni     Hydro     Hydro   \n",
       "ATIATI2201       ATI  ATI2201     MRPL       atiamuri     Hydro     Hydro   \n",
       "NaN              NaN  AVI2201     MERI       aviemore     Hydro     Hydro   \n",
       "\n",
       "           Trading_date      TP1      TP2      TP3  ...   TP39   TP40   TP41  \\\n",
       "ARAARA2201      1/08/97  29230.0  29100.0  29470.0  ...  35320  33900  33790   \n",
       "NaN             1/08/97      NaN      NaN      NaN  ...   3928   3888   3892   \n",
       "ARIARI1101      1/08/97  81510.0  81330.0  64800.0  ...  83180  83640  76160   \n",
       "ATIATI2201      1/08/97  19200.0  15270.0  15030.0  ...  37420  34650  29350   \n",
       "NaN             1/08/97  87970.0  87880.0  87770.0  ...  81980  74380  67190   \n",
       "\n",
       "             TP42   TP43   TP44   TP45   TP46   TP47   TP48  \n",
       "ARAARA2201  30310  27580  27110  27200  27310  27330  27260  \n",
       "NaN           908      6      0      0      0      0      0  \n",
       "ARIARI1101  72360  63180  62640  62310  63050  63130  54020  \n",
       "ATIATI2201  29650  29670  23190  19910  17830  17930  17550  \n",
       "NaN         53040  45970  47080  50350  50870  51740  52350  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_id = df_gen.Site_Code + df_gen.POC_Code.astype(str)\n",
    "df_gen_newind = df_gen.copy()\n",
    "df_gen_newind.index = gen_id\n",
    "df_gen_newind.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks okay, but let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_newind.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, indices need not be unique. Our choice is not unique because there are multiple samples with the same `Site_Code` and `POC_Code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(df_gen_newind.index).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important consequence of a non-unique index is that indexing by label will return multiple values for some labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_newind.loc['HLYHLY2201']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn more about indexing below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a truly unique index by combining `POC_Code` and `Trading_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = df_gen.POC_Code  + df_gen.Trading_date\n",
    "df_gen_unique = df_gen.copy()\n",
    "df_gen_unique.index = unique_id\n",
    "df_gen_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and you may ask why do we need a truly unique index? \n",
    "\n",
    "![alt_text](https://i.stack.imgur.com/1ejWY.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice the missing values where Pandas has read them as `NaN`\n",
    "Missing values can be filled as desired, either with selected values, or by rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['Site_Code'] = df_gen['Site_Code'].fillna(\"Unknown\")\n",
    "df_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can replace the rest of `NaN` with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen=df_gen.fillna(0)\n",
    "df_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that `reindex` does not work if we pass a non-unique index series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove rows or columns via the `drop` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, let's see how many rows and columns do we have\n",
    "df_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.drop([4, 1326])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.drop(['TP1','TP2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section discusses methods to select data from Pandas dataframe. First, let's create a series named `Fuel` with all the Fuel_Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Series object\n",
    "Fuel = df_gen_unique.Fuel_Code\n",
    "Fuel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose the first three items in the Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing\n",
    "Fuel[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's choose specific values from one index to another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can slice with data labels, since they have an intrinsic order within the Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fuel['ARA22011/08/97':'TMU110131/08/97']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can also modify the data, let's force all the data selected to 'Solar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fuel.loc['ARA22011/08/97':'TMU110131/08/97'] = 'Solar'\n",
    "Fuel['ARA22011/08/97':'TMU110131/08/97']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a `DataFrame` we can slice along either or both axes. Let's select a smaller Dataframe of `Fuel_Code` and `Tech_Code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique[['Fuel_Code','Tech_Code']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there are data points where 'TP1' is zero, so let's filter them out. Note that we have to assign the value to itself or to another data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique = df_gen_unique[df_gen_unique.TP1>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the labels, we can use indexing field `loc` to select subsets of rows and columns in an intuitive way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.loc['TKA011131/08/97', ['Gen_Code','Fuel_Code', 'Tech_Code', 'TP1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose multiple rows and columns, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.loc[['AVI22011/08/97','BEN22021/08/97'], ['Gen_Code','Fuel_Code', 'Tech_Code', 'TP1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.loc[:'BEN22021/08/97', 'Fuel_Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's if we want to select columns and rows with the numeric position of their rows and columns ?\n",
    "\n",
    "We use `iloc` instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.iloc[1:3,2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what's if we want a mix between the string label and the numeric values? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.loc[['AVI22011/08/97','BEN22021/08/97'], df_gen_unique.columns[1:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.loc[ df_gen_unique.index[0:3], ['Gen_Code','Fuel_Code']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `groupby` to select data of specific conditions\n",
    "\n",
    "For instance, let's select al generators of different types ('Diesel', 'Hydro' and 'Solar') and then calculate the mean, minimum and maximum of `TP1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean0 = df_gen_unique.groupby('Fuel_Code').TP1.mean()\n",
    "min0 = df_gen_unique.groupby('Fuel_Code').TP1.min()\n",
    "max0 = df_gen_unique.groupby('Fuel_Code').TP1.max()\n",
    "\n",
    "print('Mean value = \\n',mean0,'\\n Minimum value = \\n',min0,'\\n Maximum value = \\n',max0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Groupby` can also be applied with multiple conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.groupby(['Fuel_Code','Tech_Code']).TP1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data Operations\n",
    "\n",
    "`DataFrame` and `Series` objects allow for several operations to take place either on a single object, or between two or more objects.\n",
    "\n",
    "For example, we can perform arithmetic on the elements of two objects, such as combining baseball statistics across years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hydro1 = pd.Series(df_gen.TP1[df_gen.Tech_Code=='Hydro'].values)\n",
    "Thrml1 = pd.Series(df_gen.TP1[df_gen.Tech_Code=='Thrml'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tech_total = Hydro1 + Thrml1\n",
    "Tech_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a lot of `NaN` because Pandas' data alignment places `NaN` values for labels that do not overlap in the two Series. In fact, there are only 264 sites that have both `Hydro` and `Thrml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tech_total[Tech_total.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we do want the operation to honor the data labels in this way, we probably do not want the missing values to be filled with `NaN`. We can use the `add` method to calculate `TP1` totals by using the `fill_value` argument to insert a zero where labels do not overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hydro1.add(Thrml1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations can also be **broadcast** between rows or columns.\n",
    "\n",
    "For example, if we subtract the maximum `TP1` value from the `hr` column, we get how many fewer than the maximum were by each site: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.TP1 - df_gen.TP1.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, looking at things row-wise, we can see how a particular site compares with the rest of the group with respect to important statistics. Let's look at site 1000 and see how is it diffeerent to the rest in terms of TP1 to TP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df_gen[['TP1','TP2', 'TP3', 'TP4']]\n",
    "diff = stats - stats.iloc[1000]\n",
    "diff[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply functions to each column or row of a `DataFrame`. Let's see the median of TP1 to TP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to do more complicated calculations that Pandas does not natively support, \n",
    "a trick to use is to develop a `lambda` function that can be applied accross the dataframe\n",
    "\n",
    "For instance here we want to know the different between the maximum and minimum values of `TP1` to `TP4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_range = lambda x: x.max() - x.min()\n",
    "stats.apply(stat_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use apply to calcuate a weighted sum of values. This also an example of how we can write equations in Markdown\n",
    "\n",
    "$$SLG = \\frac{TP1 + (2 \\times TP2) + (3 \\times TP3) + (4 \\times TP4)}{TP1+TP2+TP3+TP4+100}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq1 = lambda x: (x['TP1']+ 2*x['TP2'] + 3*x['TP3'] + 4*x['TP4'])/(x['TP1']+x['TP2']+x['TP3']+x['TP4']+100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.apply(eq1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Sorting and Ranking\n",
    "\n",
    "Pandas objects include methods for re-ordering data. First, let's try to sort the index of our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.sort_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort in descending order\n",
    "df_gen_unique.sort_index(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to sort the columns instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the columns\n",
    "df_gen_unique.sort_index(axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `sort_values` to sort by value, rather than by the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.TP1.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a `DataFrame`, we can sort according to the values of one or more columns using the `by` argument of `sort_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique[['Fuel_Code','TP1','TP2']].sort_values(ascending=[False,True], by=['TP1', 'TP2']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking** does not re-arrange data, but instead returns an index that ranks each value relative to others in the Series. Let's rank the generators according to their `TP1` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.TP1.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ties are assigned the mean value of the tied ranks, which may result in decimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([100,100]).rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can break ties via one of several methods, such as by the order in which they occur in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique.TP1.rank(method='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When multiple columns are selected, the rank for each column will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_unique[['TP1','TP2','TP3']].rank(ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Calculate another  **weighted sum** of each generator in `df_gen_unique`, and return the ordered series of estimates.\n",
    "\n",
    "$$eq2 = \\frac{TP3 + TP5^2 - 5*TP7}{TP9 - 4*TP11 + TP13 + 200}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Hierarchical indexing\n",
    "\n",
    "In the electricity generation example, we combined 2 fields to obtain a unique index that was not simply an integer value. A more elegant way to have done this would be to create a hierarchical index from the three fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_id = df_gen.set_index(['POC_Code', 'Trading_date'])  \n",
    "df_gen_id.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This index is a `MultiIndex` object that consists of a sequence of tuples, the elements of which is some combination of the two columns used to create the index. Where there are multiple repeated values, Pandas does not print the repeats, making it easy to identify groups of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_id.index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can check whether the index is unique or not\n",
    "df_gen_id.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_id.loc[('ARG1101',  '1/08/97')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-indexing can be done when we read CSV data, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen = pd.read_csv(\"../Data/Electricity/generation2.csv\", index_col=['POC_Code', 'Trading_date'])\n",
    "df_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a hierachical index, we can select subsets of the data based on a *partial* index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.loc['ARI1101']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical indices can be created on either or both axes. Here is a trivial example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "frame = pd.DataFrame(np.arange(12).reshape(( 4, 3)), \n",
    "                  index =[['a', 'a', 'b', 'b'], [1, 2, 1, 2]], \n",
    "                  columns =[['Auckland', 'Auckland', 'Wellington'], ['Green', 'Red', 'Green']])\n",
    "\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to get fancy, both the row and column indices themselves can be given names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.index.names = ['key1', 'key2']\n",
    "frame.columns.names = ['City', 'Color']\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can do all sorts of custom indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.loc['a']['Auckland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.loc['b', 2]['Wellington']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the order of the set of indices in a hierarchical `MultiIndex` can be changed by swapping them pairwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_id.swaplevel('POC_Code', 'Trading_date').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Missing data\n",
    "\n",
    "The occurence of missing data is so prevalent that it pays to use tools like Pandas, which seamlessly integrates missing data handling so that it can be dealt with easily, and in the manner required by the analysis at hand.\n",
    "\n",
    "Missing data are represented in `Series` and `DataFrame` objects by the `NaN` floating point value. However, `None` is also treated as missing, since it is commonly used as such in other contexts (*e.g.* NumPy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pd.Series([np.nan, -3, None, 'foobar'])\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values may be dropped or indexed out:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `dropna` drops entire rows in which one or more values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be overridden by passing the `how='all'` argument, which only drops a row when every field is a missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be customized further by specifying how many values need to be present before a row is dropped via the `thresh` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.dropna(thresh=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to drop missing values column-wise instead of row-wise, we use `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than omitting missing data from an analysis, in some cases it may be suitable to fill the missing value in, either with a default value (such as zero) or a value that is either imputed or carried forward/backward from similar data points. We can do this programmatically in Pandas with the `fillna` argument. First, let's fill all missing value with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify condition in each column to fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.fillna({'TP1': 100, 'Fuel_Code':'Hydro'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `fillna` by default returns a new object with the desired filling behavior, rather than changing the `Series` or  `DataFrame` in place (**in general, we like to do this, by the way!**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can alter values in-place using `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.TP1.fillna(100, inplace=True)\n",
    "df_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values can also be interpolated, using any one of a variety of methods: \n",
    "Read more here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or we can fill with the mean value of the column\n",
    "df_gen.fillna(df_gen.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Data summarization\n",
    "\n",
    "We often wish to summarize data in `Series` or `DataFrame` objects, so that they can more easily be understood or compared with similar data. The Pandas package contains several functions that are useful here, but several summarization or reduction methods are built into Pandas data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful summarization that gives a quick snapshot of multiple statistics for a `Series` or `DataFrame` is `describe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`describe` can detect non-numeric data and sometimes yield useful information about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.Site_Code.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate summary statistics *across* multiple columns, for example, correlation and covariance.\n",
    "\n",
    "$$cov(x,y) = \\sum_i (x_i - \\bar{x})(y_i - \\bar{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.TP1.cov(df_gen.TP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$corr(x,y) = \\frac{cov(x,y)}{(n-1)s_x s_y} = \\frac{\\sum_i (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_i (x_i - \\bar{x})^2 \\sum_i (y_i - \\bar{y})^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.TP1.corr(df_gen.TP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.TP1.corr(df_gen.TP45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple function can give us the whole correlation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a `DataFrame` with a hierarchical index (or indices), summary statistics can be applied with respect to any of the index levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.sum(level='Trading_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Merging and appending data\n",
    "\n",
    "Sometimes we have to merge data together. Pandas also supports this operation\n",
    "\n",
    "First, we slide data to take two Dataframes for `Coal` and `Hydro` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_gen_unique.loc[df_gen_unique.Fuel_Code=='Coal','Site_Code':'Fuel_Code']\n",
    "\n",
    "df2 = df_gen_unique.loc[df_gen_unique.Fuel_Code=='Hydro','Site_Code':'Fuel_Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the slide to have a look\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now combine `df1` and `df2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = df1.append(df2)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Writing Data to Files\n",
    "\n",
    "As well as being able to read several data input formats, Pandas can also export data to a variety of storage formats. We will bring your attention to just a couple of these.\n",
    "\n",
    "First we do a simple export to csv file to the same folder our code is in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `to_csv` method writes a `DataFrame` to a comma-separated values (csv) file. You can specify custom delimiters (via `sep` argument), how missing values are written (via `na_rep` argument), whether the index is writen (via `index` argument), whether the header is included (via `header` argument), among other options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An efficient way of storing data to disk is in binary format. Pandas supports this using Python’s built-in pickle serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.to_pickle(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complement to `to_pickle` is the `read_pickle` function, which restores the pickle to a `DataFrame` or `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
